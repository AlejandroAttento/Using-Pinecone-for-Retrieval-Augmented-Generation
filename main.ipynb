{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from pinecone import Pinecone\n",
    "\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.vectorstores import Pinecone as VSPinecome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFORMATION_PATH = \"pdfs\"\n",
    "INDEX_NAME = \"pinecone-test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Pinecone connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(\n",
    "    api_key=os.getenv(\"PINECONE_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize OpenAI LLM connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFDirectoryLoader(INFORMATION_PATH)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=200)\n",
    "text_chunks = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up OpenAI embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_search = VSPinecome.from_texts(\n",
    "    [chunk.page_content for chunk in text_chunks],\n",
    "    embedding,\n",
    "    index_name=INDEX_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='More succinctly, we can write it as\\nwhere the matrix  is the matrix whose rows are . Note that the querying vector, , is not necessarily the same asthe key-value vector . In fact, it is theoretically possible for query, key, and value vectors to all be different, though that israrely done in practice.'),\n",
       " Document(metadata={}, page_content='This attention scheme has been compared to the Query-Key analogy of relational databases. That comparison suggests an asymmetric role for the Query and Keyvectors, where one item of interest (the Query vector \"that\") is matched against all possible items (the Key vectors of each word in the sentence). However,Attention\\'s parallel calculations matches all words of a sentence with itself; therefore the roles of these vectors are symmetric. Possibly because the simplisticdatabase analogy is'),\n",
       " Document(metadata={}, page_content='This is then used to compute the context vector:\\nwhere  are the value vectors, linearly transformed by another matrix to provide the model with freedom to find the best way torepresent values. Without the matrices , the model would be forced to use the same hidden vector for both key and value, which might not beappropriate, as these two tasks are not the same.'),\n",
       " Document(metadata={}, page_content='The decoder first processes the \"<start>\" input partially, to obtain an intermediate vector , the 0th hidden vector of decoder.Then, the intermediate vector is transformed by a linear map  into a query vector . Meanwhile, the hiddenvectors outputted by the encoder are transformed by another linear map  into key vectors. The linear maps are useful for providing the model with enough freedom to find the best way to represent the data.')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"What is the key vector?\"\n",
    "doc_search.similarity_search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the Vector DB for Retrieval-Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"refine\",\n",
    "    retriever=doc_search.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n'\n",
      " '\\n'\n",
      " 'The key vector is a fundamental component of the attention mechanism in deep '\n",
      " 'learning. It is used to calculate the similarity between the query and the '\n",
      " 'key vectors, which in turn determines the importance of different parts of '\n",
      " 'the input data. This process is similar to the Query-Key analogy of '\n",
      " 'relational databases, where the query vector is matched against all possible '\n",
      " 'key vectors. However, in attention, the roles of the query and key vectors '\n",
      " 'are symmetric as all words of a sentence are matched with each other. This '\n",
      " 'allows for more comprehensive and parallel calculations, improving the '\n",
      " \"model's performance. Therefore, the key vector serves as an essential \"\n",
      " 'component in the attention mechanism, enabling the model to effectively '\n",
      " 'process and understand complex data. Additionally, the key vector is used to '\n",
      " 'compute the context vector, which is formed by linearly transforming the '\n",
      " 'value vectors. This allows the model to have more flexibility in '\n",
      " 'representing the values, as using the same hidden vector for both key and '\n",
      " 'value tasks may not be optimal. In the context of the encoder-decoder '\n",
      " 'architecture, the key vector is obtained by transforming the hidden vectors '\n",
      " 'outputted by the encoder through a linear map. This provides the model with '\n",
      " 'enough freedom to find the best way to represent the input data. Overall, '\n",
      " 'the key vector is a crucial factor in the attention mechanism, allowing for')\n"
     ]
    }
   ],
   "source": [
    "answer = qa.invoke(query)\n",
    "\n",
    "pprint(answer.get(\"result\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
